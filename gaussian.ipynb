{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-probability estimation using gaussians as the example distribution, and differentiable cost functions\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.func import grad\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# define the cost function\n",
    "def cost_function(x, y):\n",
    "    return x**2 + y\n",
    "\n",
    "cost_threshold = -5\n",
    "\n",
    "def density(x, y):\n",
    "    return torch.exp(-(x**2 + y**2) / 2) / np.sqrt(2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlims = (-10, 10)   \n",
    "# ylims = (-10, 10)\n",
    "\n",
    "xlims = (-10, 10)\n",
    "ylims = (-10, 10)\n",
    "\n",
    "xs, ys = torch.linspace(ylims[0], ylims[1], 500), torch.linspace(xlims[0], xlims[1], 500)\n",
    "xs, ys = torch.meshgrid(xs, ys)\n",
    "\n",
    "densities = density(xs, ys)\n",
    "\n",
    "print(densities.shape)\n",
    "\n",
    "# Calculate cost function values\n",
    "costs = cost_function(xs, ys)\n",
    "\n",
    "print(costs.shape)\n",
    "\n",
    "plt.contour(ys, xs, costs, levels=[cost_threshold], colors='red')\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(ylims)\n",
    "plt.imshow(densities, extent=xlims + ylims, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability that cost is less than threshold by integrating\n",
    "# the indicator function times the density over the plane\n",
    "\n",
    "# Create indicator function (1 where cost < threshold, 0 otherwise)\n",
    "indicator = (costs < cost_threshold).float()\n",
    "\n",
    "print(indicator.shape, densities.shape)\n",
    "\n",
    "# Multiply by density\n",
    "integrand = indicator * densities\n",
    "\n",
    "# Calculate area element (dx * dy)\n",
    "dx = (xlims[1] - xlims[0]) / (costs.shape[1] - 1)\n",
    "dy = (ylims[1] - ylims[0]) / (costs.shape[0] - 1)\n",
    "area_element = dx * dy\n",
    "\n",
    "# Integrate over plane by summing and multiplying by area element\n",
    "probability = integrand.sum() * area_element\n",
    "\n",
    "print(f\"Probability that cost is less than {cost_threshold}: {probability:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot conditional density\n",
    "conditional_density = densities.clone()\n",
    "conditional_density[costs >= cost_threshold] = 0\n",
    "\n",
    "# Normalize by dividing by the integral (mean * area)\n",
    "area = (xlims[1] - xlims[0]) * (ylims[1] - ylims[0])\n",
    "conditional_density = conditional_density / (conditional_density.mean() * area)\n",
    "\n",
    "\n",
    "plt.imshow(conditional_density, extent=xlims + ylims, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, to sample from the conditional density, we sample from p'(x) \\propto p(x) * exp(max(0, \\beta * cost(x)))\n",
    "\n",
    "# def prior_density(xs):\n",
    "#     # xs: (n, 2)\n",
    "#     return torch.exp(-(xs**2).sum(dim=1) / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "# cost_threshold = -5\n",
    "\n",
    "def log_prior_density(xs):\n",
    "    # xs: (n, 2)\n",
    "    return - (xs**2).sum(dim=1) / 2\n",
    "\n",
    "def log_cost(xs):\n",
    "    # xs: (n, 2)\n",
    "    return xs[:, 1]**2 + xs[:, 0]\n",
    "\n",
    "def log_conditional_density(xs, beta):\n",
    "    log_costs = -torch.relu(beta * (log_cost(xs) - cost_threshold))\n",
    "    # exp_costs = 1\n",
    "    log_prior_densities = log_prior_density(xs)\n",
    "\n",
    "    if torch.any(torch.isnan(log_prior_densities + log_costs)):\n",
    "        print(xs)\n",
    "        print(log_prior_densities)\n",
    "        print(log_costs)\n",
    "        raise ValueError(\"NaN values in conditional density\")\n",
    "\n",
    "    return log_prior_densities + log_costs\n",
    "    # return log_costs\n",
    "\n",
    "def sample_step(xs_t, beta, step_size):\n",
    "    # Langevin dynamics step\n",
    "    # Calculate gradient of log density\n",
    "    xs_t.requires_grad_(True)\n",
    "    log_density = log_conditional_density(xs_t, beta)\n",
    "    grad_log_density = torch.autograd.grad(log_density.sum(), xs_t)[0]\n",
    "\n",
    "    if torch.any(torch.isnan(grad_log_density)):\n",
    "        points_with_nan = xs_t[torch.any(torch.isnan(grad_log_density), dim=1)]\n",
    "        print(points_with_nan)\n",
    "        costs = log_cost(points_with_nan)\n",
    "        densities = log_conditional_density(points_with_nan, beta)\n",
    "        grads = torch.autograd.grad(densities.sum(), points_with_nan)[0]\n",
    "        print(grads)\n",
    "        raise ValueError(\"NaN values in gradient of log density\")\n",
    "    \n",
    "    # Update with gradient and noise\n",
    "    noise = torch.randn_like(xs_t) * np.sqrt(2 * step_size)\n",
    "    xs_next = xs_t + step_size * grad_log_density + noise\n",
    "    \n",
    "    return xs_next.detach()\n",
    "\n",
    "xs = torch.randn(10_000, 2, dtype=torch.float64)\n",
    "\n",
    "print(xs.shape)\n",
    "\n",
    "# Run chain with decaying parameters\n",
    "n_steps = 10000\n",
    "beta_start = 10.0\n",
    "beta_end = 100.0\n",
    "step_size_start = 0.001\n",
    "step_size_end = 0.000001\n",
    "\n",
    "image_idx = 0\n",
    "\n",
    "for i in tqdm.tqdm(range(n_steps)):\n",
    "    progress = i / (n_steps-1)\n",
    "    # Exponentially decay step size\n",
    "    step_size = step_size_start * (step_size_end/step_size_start)**progress\n",
    "    # Linearly grow beta\n",
    "    beta = beta_start + progress * (beta_end - beta_start)\n",
    "    \n",
    "    # plot xs, save image\n",
    "    if i % 100 == 0:\n",
    "        plt.hist2d(xs[:, 0], xs[:, 1], bins=100, range=[[-10, 0], [-5, 5]], cmap='plasma', density=True, vmin=0, vmax=6)\n",
    "        plt.colorbar()\n",
    "        # plt.scatter(xs[:, 0], xs[:, 1], s=0.1, marker='.', c='red', alpha=0.1)\n",
    "        # plt.xlim(-10, 0)\n",
    "        # plt.ylim(-5, 5)\n",
    "        plt.title(f'beta: {beta:.2f}, lr: {step_size:.2e}')\n",
    "        plt.savefig(f'images/xs_{image_idx}.png')\n",
    "        plt.close()\n",
    "        image_idx += 1\n",
    "\n",
    "    # print(step_size, step_size_end, step_size_start)\n",
    "\n",
    "    # Take MCMC step\n",
    "    xs = sample_step(xs, beta, step_size)\n",
    "\n",
    "samples = xs.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Create the GIF from saved images\n",
    "images = []\n",
    "filenames = [f\"images/xs_{i}.png\" for i in range(image_idx)]\n",
    "for filename in filenames:\n",
    "    images.append(Image.open(filename))\n",
    "    \n",
    "# Save the GIF\n",
    "images[0].save(\n",
    "    'images/animation.gif',\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    duration=50,  # Duration for each frame in milliseconds\n",
    "    loop=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_density(xs, ps, bandwidth=1):\n",
    "    # calculate the kernel density estimate of xs given the known samples ps\n",
    "    # xs: (n, d)\n",
    "    # ps: (m, d)\n",
    "    # bandwidth: float\n",
    "\n",
    "    def rbf(a, b, bandwidth):\n",
    "        return torch.exp(-((a - b).pow(2).sum(dim=-1) / (2 * bandwidth**2)))\n",
    "\n",
    "    def normalizing_constant(ps, bandwidth):\n",
    "        n = ps.shape[0]\n",
    "        dim = ps.shape[1]\n",
    "        return (2 * np.pi * bandwidth**2)**(dim / 2) * n\n",
    "\n",
    "    print(xs[:, None, :].shape)\n",
    "    print(ps[None, :, :].shape)\n",
    "\n",
    "    rbfs = rbf(xs[:, None, :], ps[None, :, :], bandwidth).sum(dim=-1)\n",
    "    print(rbfs.shape)\n",
    "    return rbfs / normalizing_constant(ps, bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = torch.meshgrid(torch.linspace(xlims[0], xlims[1], 100), torch.linspace(ylims[0], ylims[1], 100))\n",
    "\n",
    "grid_points = torch.stack([xs.flatten(), ys.flatten()], dim=1)\n",
    "\n",
    "print(grid_points.shape)\n",
    "print(samples.shape)\n",
    "\n",
    "density = kernel_density(grid_points, samples[len(samples)//2:], bandwidth=0.1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.contourf(xs.numpy(), ys.numpy(), density.reshape(100, 100).numpy())\n",
    "plt.colorbar()\n",
    "\n",
    "costs = cost_function(ys, xs)\n",
    "plt.contour(xs, ys, costs, levels=[cost_threshold], colors='red')\n",
    "\n",
    "plt.title('Kernel Density Estimate')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate the density over the grid to verify it sums to approximately 1\n",
    "dx = (xlims[1] - xlims[0]) / (xs.shape[0] - 1)\n",
    "dy = (ylims[1] - ylims[0]) / (ys.shape[0] - 1)\n",
    "\n",
    "integral = density.sum() * dx * dy\n",
    "print(f\"Integral of density: {integral.item():.4f}\")  # Should be close to 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprior_density\u001b[39m(xs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m(xs\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi)\n\u001b[0;32m----> 4\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m p_values \u001b[38;5;241m=\u001b[39m prior_density(samples[:\u001b[38;5;28mlen\u001b[39m(samples)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m((p_values \u001b[38;5;241m/\u001b[39m q_values)\u001b[38;5;241m.\u001b[39mmean())\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mkernel_density\u001b[0;34m(xs, ps, bandwidth)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(xs[:, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(ps[\u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 18\u001b[0m rbfs \u001b[38;5;241m=\u001b[39m \u001b[43mrbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(rbfs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rbfs \u001b[38;5;241m/\u001b[39m normalizing_constant(ps, bandwidth)\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mkernel_density.<locals>.rbf\u001b[0;34m(a, b, bandwidth)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrbf\u001b[39m(a, b, bandwidth):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def prior_density(xs):\n",
    "    return torch.exp(-(xs**2).sum(dim=1) / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "q_values = kernel_density(samples[:len(samples)//2], samples[len(samples)//2:], bandwidth=0.1)\n",
    "p_values = prior_density(samples[:len(samples)//2])\n",
    "\n",
    "print((p_values / q_values).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
